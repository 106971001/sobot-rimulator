OBSERVATIONS AND HYPOTHESES TO INVESTIGATE FURTHER

Wheel Encoder Behavior:
======================
The discrete nature of the wheel encoder essentially results in a discrete set of points in the world where the robot may believe it is located. It would be interesting to figure out what the complete set of such points looks like.


GTG PID Controller:
==================
When GTG controller uses angle to goal as it's error, a relatively small integral term will induce oscillations, which may be damped by the other terms.

Using the distance to the goal as the error does not work. Is this because the state-space is non-linear in such a model?

Idea behind good unicycle velocity as function of unicycle omega (angular velocity).

AO PID Controller:
=================
If it happens that all of the sensors are reporting similar distances to obstacles, the resulting avoid-obstacle heading vector behaves similarly to when none of the sensors are detecting obstacles. Thus if the robot finds itself in a very cramped place with obstacles on all sides, it will behave as if there are no obstacles - driving forward and crashing.

Blended GTG/AO Controller:
========================
A very heavy weight towards the avoid-obstacle heading seems to be necessary when there is even a small amount of clutter.

Raising the sensor gains on the side-facing sensors significantly improves the robot's ability to handle corners of obstacles.

Adding some nonlinear scaling to the sensor distances (implemented in the AO controller) seems to offer some subtle improvements to behavior. That is, having the robot react less aggressively to obstacles just barely within its sensor range, but very aggressively to obstacles it is almost colliding with. I am not commiting the code for this at this time but here is a good polynomial formula for scaling a sensor distance vector before adding it to the avoid-obstacle heading vector:
      # obstacle_vector = the real vector from the robot to the obstacle
      # d               = real sensor distance (length of obstacle_vector)
      # dmin, dmax      = min and max distances the sensor is capable of detecting
      # a               = scaling factor equal to 1.0 / ( dmax-dmin )
      # b               = exponent - should be between 0.0 and 1.0 to give desired behavior
      # with these definitions the scaling factor s will be 1.0 when d = dmax, falling at an accelarating rate as d decreases, reaching 0.0 when d = dmin:
      s = ( a*(d - dmin) )**b
      scaled_vector = linalg.scale( obstacle_vector, s )
